{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca30f2ab",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858c880b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_rare_words_mail_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>curve shift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ahead learned tragedies adversity teaches less...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phillip automated notification availability in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phillip spin win spin iwon prize machine chanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resource acceptance forms admin permanent reso...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             no_rare_words_mail_text\n",
       "0                                        curve shift\n",
       "1  ahead learned tragedies adversity teaches less...\n",
       "2  phillip automated notification availability in...\n",
       "3  phillip spin win spin iwon prize machine chanc...\n",
       "4  resource acceptance forms admin permanent reso..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# load the data\n",
    "df = pd.read_csv(\"no_rare_words_mail_text.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "496a7dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37117, 1)\n",
      "(35911, 1)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "# drop the reocrds with null values\n",
    "df = df.dropna()\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c4757fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35911, 3)\n"
     ]
    }
   ],
   "source": [
    "stopwords = [\"edi\", \"cpr\", \"basic\", \"size\", 'men', 'woman', 'trtd', 'alignleftfont', 'intercontinentalexchange', 'bfonttdtd', 'sizeb', 'sizebb',\n",
    "            'rusgopsgeotoolsaprs', 'facedarial', 'sansserif', 'widthdfont', 'colorbfont', 'sizefont', 'alignmiddlefont',\n",
    "            'tdnbsptd', 'mimeversion', 'contenttype', 'licensed', 'kcfs', 'nyisotechexchange', 'alignleft',\n",
    "             'classemailtextblack', 'arial', 'fontsize', 'fontfamily', 'colspan', 'valigntop', 'fontstyle', 'contain', 'confidential',\n",
    "            'oncall', 'sitara', 'ossuatarp', 'thur', 'eps', 'mseb', 'ampm', 'llc', 'ubsw', 'textdecoration', 'none', 'women', 'man',\n",
    "            'solely', 'responsible', 'ecn', 'kevin', 'presto', 'fontweight', 'bold', 'xms','registered', 'trademark', 'intended',\n",
    "            'recipient', 'strictly', 'prohibited', 'ddddddddddddddddddddddddd', 'published', 'behalf', 'represent',\n",
    "            'carr', 'nwn', 'midcolumbia', 'corner', 'rockies', 'tds', 'hereby', 'notified', 'restriction', 'attachment',\n",
    "            'follows', 'pt', 'throughout', 'restriction', 'representation', 'southwest', 'mid', 'subscribe', 'stop', \n",
    "            'ets', 'nothing', 'considered', 'author', 'differ', 'yahoo', 'betweeneveryone', 'terminate', 'subscription',\n",
    "            'pdt', 'widthtr', 'trtable', 'colspancash', 'span', 'span', 'classspecialredspannbspnbspnbspnbspnbspspan',\n",
    "             'tdtrtr', 'colspancash', 'adobe', 'acrobat', 'palo', 'drive', 'eol', 'opinion', 'expressed', 'respect',\n",
    "            'url', 'browser', 'paste', 'xxxx', 'anyone', 'else']\n",
    "\n",
    "# removing html content from the text\n",
    "df['html_cleaned_mail_text'] = df['no_rare_words_mail_text'].apply(lambda x: re.sub('html.*.html', \"\", x))\n",
    "df = df.dropna()\n",
    "\n",
    "# remooving the stopwords as above\n",
    "df['cleaned_mail_text'] = df['html_cleaned_mail_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "df = df.dropna()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c621809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "#from stop_words import get_stop_words\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim import corpora, models\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import re\n",
    "import pyLDAvis#.gensim\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "\n",
    "texts = []\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# we create bigrams from the cleaned text\n",
    "for i in df['cleaned_mail_text']:\n",
    "    tokens = i.split()\n",
    "    # lemmatize tokens\n",
    "    lemma_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # remove word containing only single char\n",
    "    new_lemma_tokens = [raw for raw in lemma_tokens if not len(raw) == 1]\n",
    "    lemmatized_string = \" \".join(token for token in new_lemma_tokens)\n",
    "    \n",
    "    import nltk\n",
    "    #word_data = \"The best performance can bring in sky high success.\"\n",
    "    nltk_tokens = nltk.word_tokenize(lemmatized_string)\n",
    "    #print(list(nltk.bigrams(nltk_tokens)))\n",
    "    texts.append([ele[0]+ \" \" + ele[1] for ele in list(nltk.bigrams(nltk_tokens))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5f4d3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn our tokenized documents into a id <-> term dictionary\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "# convert tokenized documents into a document-term matrix\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17d359d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([(0.0017032448, 'solicitation instrument'),\n",
      "   (0.0016340485, 'reliable accurate'),\n",
      "   (0.0016188252, 'material respect'),\n",
      "   (0.0016169606, 'accurate solicitation'),\n",
      "   (0.0016169606, 'instrument opinion'),\n",
      "   (0.0016169606, 'officer affiliate'),\n",
      "   (0.0016169606, 'opinion material'),\n",
      "   (0.0016169606, 'respect officer'),\n",
      "   (0.0013402642, 'hot link'),\n",
      "   (0.0013402642, 'clicking hot')],\n",
      "  -0.07509681347423333),\n",
      " ([(0.0029388594, 'stephanie taylor'),\n",
      "   (0.0029354566, 'esource present'),\n",
      "   (0.0025061967, 'custom clip'),\n",
      "   (0.002456986, 'basic clinic'),\n",
      "   (0.0020929791, 'fast seat'),\n",
      "   (0.0020918015, 'seat stephanie'),\n",
      "   (0.0020918015, 'fill fast'),\n",
      "   (0.0020918015, 'seat fill'),\n",
      "   (0.001676022, 'noshows charged'),\n",
      "   (0.0016663461, 'clinic pmeb')],\n",
      "  -0.19882183250570434),\n",
      " ([(0.0024026139, 'henry hub'),\n",
      "   (0.0021867852, 'los angeles'),\n",
      "   (0.0016785123, 'advance reservation'),\n",
      "   (0.0015706796, 'dallasft dfw'),\n",
      "   (0.0014474891, 'alamo rent'),\n",
      "   (0.001411202, 'embassy suite'),\n",
      "   (0.001409743, 'regis luxury'),\n",
      "   (0.0013818282, 'luxury collection'),\n",
      "   (0.0013493734, 'ohare ord'),\n",
      "   (0.001165376, 'continental airline')],\n",
      "  -8.429222110699332),\n",
      " ([(0.0017700626, 'la vega'),\n",
      "   (0.001651123, 'sapisc unify'),\n",
      "   (0.001651123, 'terminal unify'),\n",
      "   (0.0016504859, 'malcolm well'),\n",
      "   (0.0016305145, 'sunoss telephony'),\n",
      "   (0.0015461722, 'ardmore azurix'),\n",
      "   (0.0014462805, 'task force'),\n",
      "   (0.0013148234, 'vacation package'),\n",
      "   (0.0012759755, 'los angeles'),\n",
      "   (0.0012532418, 'unify sapisc')],\n",
      "  -12.828060564422263),\n",
      " ([(0.002670306, 'lehman brother'),\n",
      "   (0.0017373859, 'petroleumworld caracas'),\n",
      "   (0.0016197496, 'foreign lender'),\n",
      "   (0.001463223, 'los angeles'),\n",
      "   (0.0013522159, 'indian lender'),\n",
      "   (0.0011477788, 'mkt cap'),\n",
      "   (0.0011348452, 'cap target'),\n",
      "   (0.0011348452, 'target rank'),\n",
      "   (0.0011079672, 'arthur andersen'),\n",
      "   (0.0010974418, 'downtown club')],\n",
      "  -13.831498874085511),\n",
      " ([(0.0019001737, 'window medium'),\n",
      "   (0.0011427441, 'jay rickerts'),\n",
      "   (0.0010772891, 'peter cook'),\n",
      "   (0.00096146215, 'account payable'),\n",
      "   (0.0009569382, 'shaperect coords'),\n",
      "   (0.0009532655, 'today wrap'),\n",
      "   (0.00094121415, 'parentrandom var'),\n",
      "   (0.00094121415, 'var random'),\n",
      "   (0.00094121415, 'random parentrandom'),\n",
      "   (0.00090147177, 'spotlight tag')],\n",
      "  -13.955772148019689),\n",
      " ([(0.0014541129, 'joint proxy'),\n",
      "   (0.0010907508, 'proxy statementprospectus'),\n",
      "   (0.0010277212, 'eastern region'),\n",
      "   (0.0009920778, 'hyatt regency'),\n",
      "   (0.00089500716, 'simulation simulation'),\n",
      "   (0.00078240637, 'barry tycholiz'),\n",
      "   (0.0007121434, 'brian redmond'),\n",
      "   (0.00068861427, 'focused identifying'),\n",
      "   (0.0006581657, 'midmarket origination'),\n",
      "   (0.00061412423, 'white paper')],\n",
      "  -15.617837067761773),\n",
      " ([(0.0015831178, 'written consent'),\n",
      "   (0.0012255589, 'entity addressed'),\n",
      "   (0.0012152088, 'star war'),\n",
      "   (0.0011726464, 'nyiso reserving'),\n",
      "   (0.0011264901, 'volume increased'),\n",
      "   (0.0010009328, 'entity written'),\n",
      "   (0.0009378696, 'bulletin delivered'),\n",
      "   (0.00088221085, 'writes nyiso'),\n",
      "   (0.0008773243, 'official posting'),\n",
      "   (0.0008630499, 'forward swap')],\n",
      "  -16.807087884832242),\n",
      " ([(0.0017302429, 'resource type'),\n",
      "   (0.0015467397, 'type application'),\n",
      "   (0.0015053554, 'mary cook'),\n",
      "   (0.0012345392, 'carol clair'),\n",
      "   (0.0011732217, 'cordially mary'),\n",
      "   (0.00095898093, 'resource kobra'),\n",
      "   (0.0007964349, 'virus protection'),\n",
      "   (0.00075750775, 'fuel cell'),\n",
      "   (0.00074656244, 'antioch park'),\n",
      "   (0.00072490366, 'bin laden')],\n",
      "  -18.681277857313546),\n",
      " ([(0.0011804446, 'embedded picture'),\n",
      "   (0.0010695903, 'picture metafile'),\n",
      "   (0.0010540556, 'restriction restriction'),\n",
      "   (0.0009357971, 'matching gift'),\n",
      "   (0.0009232056, 'advice ehronline'),\n",
      "   (0.0009126317, 'crude refined'),\n",
      "   (0.0007859516, 'print advice'),\n",
      "   (0.0007750364, 'external reputation'),\n",
      "   (0.00074434147, 'pt pt'),\n",
      "   (0.000654552, 'cindy olson')],\n",
      "  -19.91627615748462)]\n"
     ]
    }
   ],
   "source": [
    "# lda model with 10 topics\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=10, id2word = dictionary, passes=20)\n",
    "import pprint\n",
    "\n",
    "# printing the topics to analyse the terms that contribute to that topic\n",
    "pprint.pprint(ldamodel.top_topics(corpus,topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37391f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -18.707536268377158\n",
      "\n",
      "Coherence Score:  0.47771410229462513\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', ldamodel.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=ldamodel, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3d319d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05c2a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265dfd88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e5813f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
